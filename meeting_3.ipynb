{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install chromadb"
      ],
      "metadata": {
        "id": "gfsDoKfLtZAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentence_transformers beautifulsoup4 requests"
      ],
      "metadata": {
        "id": "qZ-iEZJZsNLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7KFcEBYrpKL"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup # we use BeatifulSoup for webscraping\n",
        "term = \"202610\" #2025-2026 course catalog\n",
        "base_url = \"https://courses.rice.edu\"\n",
        "url_catalog = base_url + \"/admweb/!SWKSCAT.cat?p_action=CATALIST&p_term=\" + term # scrape data from courses.rice.edu\n",
        "\n",
        "# Get the HTML code of the page\n",
        "resp = requests.get(url_catalog)\n",
        "html_source = resp.text\n",
        "\n",
        "soup = BeautifulSoup(html_source, \"html.parser\") # our scraper\n",
        "\n",
        "courses = []\n",
        "\n",
        "for row in soup.select(\"tr\"): # iterate through each table row\n",
        "    cells = row.find_all(\"td\") # get all table data  cells in current table row\n",
        "    if len(cells) > 4 and cells[0].find(\"a\"): # skip rows that don't have enough cells (header or blank rows)\n",
        "        course_info = {\n",
        "            \"course\": cells[0].text.strip(),\n",
        "            \"title\": cells[1].text.strip(),\n",
        "            \"distribution_group\": cells[2].text.strip(),\n",
        "            \"diversity_credit\": cells[3].text.strip() != \"\",\n",
        "            \"credit_hours\": cells[4].text.strip(),\n",
        "        }\n",
        "\n",
        "        # Get the url\n",
        "        link_tag = cells[0].find(\"a\")\n",
        "        relative_url = link_tag['href']\n",
        "        full_url = base_url+relative_url\n",
        "\n",
        "        #Here, scrape the data from sub-page.\n",
        "\n",
        "        print(f\"  Scraping sub-page for {course_info['course']}...\")\n",
        "        # Make a new request to the course-specific page\n",
        "        course_resp = requests.get(full_url)\n",
        "        course_resp.raise_for_status()\n",
        "\n",
        "        # Create a new soup object for the course page\n",
        "        course_soup = BeautifulSoup(course_resp.text, \"html.parser\")\n",
        "\n",
        "        # Scrape the Department\n",
        "        department_b_tag = course_soup.find(\n",
        "            lambda tag: tag.name == 'b' and \"Department:\" in tag.get_text()\n",
        "        )\n",
        "\n",
        "        if department_b_tag:\n",
        "            # .next_sibling gets the text node after <b>, strip() cleans whitespace\n",
        "            course_info['department'] = department_b_tag.next_sibling.strip()\n",
        "        else:\n",
        "            course_info['department'] = \"No department found.\"\n",
        "\n",
        "        #Scrape the Grade Mode\n",
        "        grade_mode_b_tag = course_soup.find(\n",
        "            lambda tag: tag.name == 'b' and \"Grade Mode:\" in tag.get_text()\n",
        "        )\n",
        "        if grade_mode_b_tag:\n",
        "            course_info['grade mode'] = grade_mode_b_tag.next_sibling.strip()\n",
        "        else:\n",
        "            course_info['grade mode'] = \"No grade mode found.\"\n",
        "\n",
        "        #Scrape the Course Type\n",
        "        course_type_b_tag = course_soup.find(\n",
        "            lambda tag: tag.name == 'b' and \"Course Type:\" in tag.get_text()\n",
        "        )\n",
        "        if course_type_b_tag:\n",
        "\n",
        "            course_info['course type'] = course_type_b_tag.next_sibling.strip()\n",
        "        else:\n",
        "            course_info['course type'] = \"No course type found.\"\n",
        "\n",
        "        # Scrape the Restrictions\n",
        "        restrictions_b_tag = course_soup.find(\n",
        "            lambda tag: tag.name == 'b' and \"Restrictions:\" in tag.get_text()\n",
        "        )\n",
        "        if restrictions_b_tag:\n",
        "            # Find all <div>s that are siblings *after* the <b> tag\n",
        "            restriction_divs = restrictions_b_tag.find_next_siblings(\"div\")\n",
        "            restrictions_list = [div.text.strip() for div in restriction_divs]\n",
        "            # Join them with a new line\n",
        "            course_info['restrictions'] = \"\\n\".join(restrictions_list)\n",
        "        else:\n",
        "            course_info['restrictions'] = \"No restrictions found.\"\n",
        "\n",
        "        # Scrape the Prerequisites\n",
        "        prereqs_b_tag = course_soup.find(\n",
        "            lambda tag: tag.name == 'b' and \"Prerequisite(s):\" in tag.get_text()\n",
        "        )\n",
        "        if prereqs_b_tag:\n",
        "            course_info['prerequisites'] = prereqs_b_tag.next_sibling.strip()\n",
        "        else:\n",
        "            course_info['prerequisites'] = \"No prerequisites found.\"\n",
        "\n",
        "        # Scrape the Description\n",
        "        description_b_tag = course_soup.find(\n",
        "            lambda tag: tag.name == 'b' and \"Description:\" in tag.get_text()\n",
        "        )\n",
        "        if description_b_tag and description_b_tag.next_sibling:\n",
        "            course_info['description'] = description_b_tag.next_sibling.strip()\n",
        "        else:\n",
        "            course_info['description'] = \"No description found.\"\n",
        "\n",
        "        # Add the combined data to your list\n",
        "        courses.append(course_info)\n",
        "\n",
        "for course in courses:\n",
        "    print(course)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import json\n",
        "\n",
        "filename = \"courses.json\"\n",
        "\n",
        "\n",
        "with open(filename, 'w') as json_file:\n",
        "    json.dump(courses, json_file, indent=4)\n",
        "'''"
      ],
      "metadata": {
        "id": "-jt3ycIwMmee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('courses.json', 'r') as f:\n",
        "    courses = json.load(f)\n"
      ],
      "metadata": {
        "id": "xR1K0_l9ue-E"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "documents = []\n",
        "metadatas = []\n",
        "ids = []\n",
        "id = 0\n",
        "\n",
        "for course in courses:\n",
        "  doc_text = f\"Course: {course['title']} : {course['course']}. Description: {course['description']}.\"\n",
        "  documents.append(doc_text)\n",
        "  metadatas.append(course)\n",
        "  ids.append(str(id))\n",
        "  id += 1\n",
        "\n",
        "embeddings = model.encode(documents, show_progress_bar=True)"
      ],
      "metadata": {
        "id": "NFTKQdjjwxbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "\n",
        "db_path = './rice_courses_db'\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "collection = client.get_or_create_collection(\"rice_courses\")\n",
        "\n",
        "# Set a batch size safely under the 5461 limit. 5000 is a safe, round number.\n",
        "batch_size = 5000\n",
        "total_items = len(ids)\n",
        "num_batches = ((total_items + batch_size - 1) // batch_size) #ceil of division\n",
        "\n",
        "print(f\"Total items: {total_items}. Batch size: {batch_size}. Sending in {num_batches} batches...\")\n",
        "\n",
        "for i in range(0, total_items, batch_size):\n",
        "\n",
        "    # Calculate the end index for the current batch\n",
        "    end_index = min(i + batch_size, total_items)\n",
        "\n",
        "    print(f\"Adding batch {i // batch_size + 1}/{num_batches} (items {i} to {end_index})...\")\n",
        "\n",
        "    # Get the sublists\n",
        "    batch_embeddings = embeddings[i:end_index]\n",
        "    batch_documents = documents[i:end_index]\n",
        "    batch_metadatas = metadatas[i:end_index]\n",
        "    batch_ids = ids[i:end_index]\n",
        "\n",
        "    collection.add(\n",
        "        embeddings=batch_embeddings,\n",
        "        documents=batch_documents,\n",
        "        metadatas=batch_metadatas,\n",
        "        ids=batch_ids\n",
        "        )"
      ],
      "metadata": {
        "id": "lVlZWtTtx8T4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = collection.query(\n",
        "    query_texts = [\"\"],\n",
        "    n_results = 1, # by default returns 10 closest results\n",
        "    where={\n",
        "        \"$and\": [\n",
        "            {\"distribution_group\": {\"$eq\": \"Distribution Group II\"}},\n",
        "            {\"diversity_credit\": {\"$eq\": True}}\n",
        "        ]\n",
        "    }\n",
        ")\n",
        "print(results[\"documents\"])\n",
        "print(results[\"metadatas\"])\n",
        "print(results[\"distances\"])"
      ],
      "metadata": {
        "id": "IanNo_aBuDpW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}